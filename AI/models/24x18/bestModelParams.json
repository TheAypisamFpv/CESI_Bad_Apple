{
    "layers": [
        432,
        3888,
        1105,
        10800
    ],
    "dropoutRates": [
        0.269765
    ],
    "l2Reg": 7.6e-05,
    "learningRate": 0.005832,
    "inputActivation": "relu",
    "hiddenActivation": "relu",
    "outputActivation": "relu",
    "loss": "l1",
    "optimizer": "adam",
    "batch_size": 300,
    "epochs": 500,
    "fitness": 0.8331274650664864
}